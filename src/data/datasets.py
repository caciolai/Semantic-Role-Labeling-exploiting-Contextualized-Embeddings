from typing import *

import os
import json
import torch
from torch.utils.data import Dataset, DataLoader
from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence
import tqdm

def load_data(folder: str, fname: str) -> List[Dict]:
    """
    Loads the data in a suitable format.

    Args:
        folder: The folder of the dataset
        fname:  The filename of the dataset
    Returns:
        A list of dictionaries (json-like)
    """
    path = os.path.join(folder, fname)
    with open(path, "r") as f:
        data = json.load(f)

    data = [(k, v) for k, v in data.items()]
    data = [v for k, v in sorted(data, key=lambda item: item[0])]
    
    # converting predicate index for role to int
    for elem in data:
        elem["roles"] = {int(k): v for k, v in elem["roles"].items()}

    return data


class CustomDataset(Dataset):
    def __init__(self, sentences: List[Dict[str, Any]]):
        """
        Custom dataset class for task 34 (argument identification, argument classification)
        """

        self.data = self._preprocess_data(sentences)
        self.bert_embeddings = None
        self.encoded_data = None
    
    def _preprocess_data(self, sentences: List[dict]) -> List[dict]:
        """
        Preprocess a list of sentences from a raw dataset.

        Args:
            sentences: list of sentences to process
        
        Returns:
            processed data.
        """
        data = []
        for i, s in enumerate(sentences):
            predicates = [(j, p) for j, p in enumerate(s["predicates"]) if p != "_"]
            
            item = {
                "words": s["words"],
                "predicates": predicates,
                "roles": s["roles"],
                "lemmas": s["lemmas"],
                "pos_tags": s["pos_tags"]
            }
            data.append(item)

        return data

    # def bert_embed_data(self, bert_embedder):
    #     """
    #     Employs a BERT embedder object to build the BERT embeddings of the sentences
    #     in the dataset, then stored to be used in encoding later.

    #     Args:
    #         bert_embedder: see BERTEmbedder class.
    #     """
    #     self.bert_embeddings = []
    #     for item in tqdm(self.data, desc="Embedding sentences"):
    #         sent = item["words"]
    #         embedded_sentence = bert_embedder.embed_sentences(sent)
    #         self.bert_embeddings.append(embedded_sentence)

    def encode_data(self, srl_vocab, pf_vocab, words_vocab, lemmas_vocab, pos_vocab,
                    bert_embeddings):
        """
        Encodes data to be processed by the collate function that expects tensors.

        Args:
            srl_vocab, ..., pos_vocab: vocabularies for 
                                            semantic roles
                                            predicate frames
                                            words
                                            lemmas
                                            POS tags
            
            bert_embeddings:            BERT embeddings for the sentences in the dataset
        """
        self.encoded_data = []
        self.encoding_mapping = []
        encoding_idx = 0
        for i, item in tqdm(enumerate(self.data), desc="Encoding dataset", total=len(self.data)):
            # unpack preprocessed data
            preds = item["predicates"]
            roles = item["roles"]
            words = item["words"]
            lemmas = item["lemmas"]
            pos_tags = item["pos_tags"]
            bert_embedded_sentence = bert_embeddings[i]
            sentence_len = bert_embedded_sentence.shape[0]
            if len(preds) > 0:
                # duplicate multi-predicate sentences so as to have each sample
                # only containing one predicate
                for j, pred in preds:
                    # idx for predicate 
                    pred_frame = pf_vocab[pred]

                    # build a 'predicate indicator vector' to make the model aware of the position of the predicate
                    # in the sentence duplicate under consideration
                    # (seq_len x bert_dim)
                    pred_indicator_vector = torch.zeros(sentence_len, 1).to(bert_embedded_sentence.device)
                    pred_indicator_vector[j, 0] = 1
                    
                    encoded_item = {
                        "pred_frame": pred_frame,
                        "pred_indicator_vector": pred_indicator_vector,
                        "srl": torch.LongTensor(srl_vocab.encode(roles[j])),
                        "word": torch.LongTensor(words_vocab.encode(words)),
                        "lemma": torch.LongTensor(lemmas_vocab.encode(lemmas)),
                        "pos_tag": torch.LongTensor(pos_vocab.encode(pos_tags)),
                        "bert_sent": bert_embedded_sentence,
                        "pred_pos": j, # position of the predicate in the sentence
                    }

                    self.encoded_data.append(encoded_item)
            else:
                # treat separately sentences without predicates
                # (seq_len x bert_dim)
                pred_indicator_vector = torch.zeros(sentence_len, 1).to(bert_embedded_sentence.device)
                blank_roles = ["_" for _ in range(sentence_len)]
                pred_frame = pf_vocab['_']
                encoded_item = {
                    "pred_frame": pred_frame,
                    "pred_indicator_vector": pred_indicator_vector,
                    "srl": torch.LongTensor(srl_vocab.encode(blank_roles)),
                    "word": torch.LongTensor(words_vocab.encode(words)),
                    "lemma": torch.LongTensor(lemmas_vocab.encode(lemmas)),
                    "pos_tag": torch.LongTensor(pos_vocab.encode(pos_tags)),
                    "bert_sent": bert_embedded_sentence,
                    "pred_pos": -1,
                }
                self.encoded_data.append(encoded_item)
            
    def get_raw_element(self, idx):
        return self.data[idx]

    def __len__(self):
        if self.encoded_data is None:
            return len(self.data)
        else:
            return len(self.encoded_data)

    def __getitem__(self, idx):
        assert self.encoded_data is not None
        return self.encoded_data[idx]


def collate(batch: List[Dict[str, torch.Tensor]]) -> Dict[str, torch.Tensor]:

    # collecting data
    pred_indicator_vectors = [sample["pred_indicator_vector"] for sample in batch]
    srl_labels = [sample["srl"] for sample in batch]
    words = [sample["word"] for sample in batch]
    lemmas = [sample["lemma"] for sample in batch]
    pos_tags = [sample["pos_tag"] for sample in batch]
    bert_sents = [sample["bert_sent"] for sample in batch]

    # tensorizing
    lengths = torch.LongTensor([sample["word"].shape[0] for sample in batch]).view(-1)
    pred_frames = torch.LongTensor([sample["pred_frame"] for sample in batch]).view(-1)
    preds_pos = torch.LongTensor([max(sample["pred_pos"], 0) for sample in batch]).view(-1)
    pred_mask = torch.LongTensor([1 if sample["pred_pos"] >= 0 else 0 for sample in batch]).view(-1)
    
    # padding
    pred_indicator_vectors = pad_sequence(pred_indicator_vectors, batch_first=True, padding_value=0)
    srl_labels = pad_sequence(srl_labels, batch_first=True, padding_value=0)
    words = pad_sequence(words, batch_first=True, padding_value=0)
    lemmas = pad_sequence(lemmas, batch_first=True, padding_value=0)
    pos_tags = pad_sequence(pos_tags, batch_first=True, padding_value=0)
    bert_sents = pad_sequence(bert_sents, batch_first=True, padding_value=0)

    bert_sents = torch.cat((bert_sents, pred_indicator_vectors), dim=-1)

    return {
        "length": lengths, 
        "srl": srl_labels, 
        "pred_frame": pred_frames,
        "word": words,
        "lemma": lemmas,
        "pos_tag": pos_tags,
        "bert_sent": bert_sents,
        "pred_pos": preds_pos,
        "pred_mask": pred_mask
    }

